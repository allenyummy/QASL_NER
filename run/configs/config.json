{
    "dataset_name": "genia",
    "dataset_script_file": "/Users/allenyummy/Documents/QASL_NER/utils/feature_generation/load_dataset_genia.py",
    "dataset_config_name": "genia_mrc",
    "max_seq_length": 512,
    "overwrite_cache": false,
    "model_name_or_path": "hfl/chinese-bert-wwm",
    "cache_dir": "../pretrained_model/cache_from_huggingface_s3/hfl/chinese-bert-wwm/",
    "output_dir": "exp/",
    "num_train_epochs": 40,
    "per_gpu_train_batch_size": 8,
    "learning_rate": 5e-5,
    "seed": 1,
    "do_train": true,
    "do_eval": true,
    "do_predict": false,
    "evaluate_during_training": true,
    "save_steps": 5000,
    "logging_steps": 1000,
    "eval_steps": 5000,
    "load_best_model_at_end": true,
    "metric_for_best_model": "eval_f1",
    "greater_is_better": true
}